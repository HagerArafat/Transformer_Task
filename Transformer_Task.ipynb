{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3vuV2PfduzKwbnM/S0q3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HagerArafat/Transformer_Task/blob/main/Transformer_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hjYZ57g1wgC",
        "outputId": "b8993d7d-2ca5-4b5e-df73-03f18089e3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['What', 'are', 'the', 'symptoms', 'of', 'diabetes']\n",
            "\n",
            "Embeddings:\n",
            "tensor([[-0.4747,  0.1867,  1.1207, -0.2936],\n",
            "        [ 0.0089, -2.1953, -1.5260,  1.6199],\n",
            "        [ 1.6481, -0.2639,  0.3676,  0.7481],\n",
            "        [-0.4106,  0.0645,  0.7197, -0.8752],\n",
            "        [-0.1234, -1.4437, -1.3458,  0.0978],\n",
            "        [-0.0047, -0.7403, -1.7534, -1.5819]])\n",
            "\n",
            "Positional Encodings:\n",
            "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  9.9995e-01,  1.0000e-04,  1.0000e+00],\n",
            "        [ 9.0930e-01,  9.9980e-01,  2.0000e-04,  1.0000e+00],\n",
            "        [ 1.4112e-01,  9.9955e-01,  3.0000e-04,  1.0000e+00],\n",
            "        [-7.5680e-01,  9.9920e-01,  4.0000e-04,  1.0000e+00],\n",
            "        [-9.5892e-01,  9.9875e-01,  5.0000e-04,  1.0000e+00]])\n",
            "\n",
            "Input with Positional Encoding (X):\n",
            "tensor([[-0.4747,  1.1867,  1.1207,  0.7064],\n",
            "        [ 0.8503, -1.1954, -1.5259,  2.6199],\n",
            "        [ 2.5574,  0.7359,  0.3678,  1.7481],\n",
            "        [-0.2694,  1.0640,  0.7200,  0.1248],\n",
            "        [-0.8802, -0.4445, -1.3454,  1.0978],\n",
            "        [-0.9636,  0.2584, -1.7529, -0.5819]])\n",
            "\n",
            "Weight Matrices:\n",
            "W_Q:\n",
            "tensor([[-0.9773, -0.5261,  0.7750, -0.6370],\n",
            "        [-1.2586,  0.4208, -0.5477, -1.2927],\n",
            "        [-0.5001, -0.6737,  1.0492, -1.2398],\n",
            "        [-0.7130, -0.3954, -0.8058, -1.3371]])\n",
            "W_K:\n",
            "tensor([[-1.3526,  0.3882, -0.9467, -2.1382],\n",
            "        [ 0.8431, -0.9590, -1.0035,  1.3942],\n",
            "        [-0.6150,  0.5773, -0.1399,  0.0559],\n",
            "        [-0.7530,  0.5185,  0.2119,  1.3433]])\n",
            "W_V:\n",
            "tensor([[-0.2585,  0.7321, -1.8116, -0.4046],\n",
            "        [ 0.1332, -0.1256,  1.6184,  0.8306],\n",
            "        [ 1.3753,  0.0296,  0.3208, -0.5982],\n",
            "        [ 0.1494,  0.3118,  0.6151,  2.2421]])\n",
            "\n",
            "Query Matrix (Q):\n",
            "tensor([[-2.0939, -0.2852, -0.4112, -3.5657],\n",
            "        [-0.4315, -0.9582, -2.3985, -0.6077],\n",
            "        [-4.8560, -1.9749,  0.5561, -5.3738],\n",
            "        [-1.5249,  0.0551, -0.1366, -2.2633],\n",
            "        [ 1.3097,  0.7485, -2.7350,  1.3355],\n",
            "        [ 1.9080,  2.0269, -2.2586,  3.2310]])\n",
            "Key Matrix (K):\n",
            "tensor([[ 0.4214, -0.3091, -0.7486,  3.6810],\n",
            "        [-3.1924,  1.9539,  1.1631, -0.0508],\n",
            "        [-4.3814,  1.4058, -2.8406, -2.0735],\n",
            "        [ 0.7247, -0.6446, -0.8870,  2.2674],\n",
            "        [ 0.8167, -0.1230,  1.7001,  2.6619],\n",
            "        [ 3.0376, -1.9356,  0.7747,  1.5412]])\n",
            "Value Matrix (V):\n",
            "tensor([[ 1.9277, -0.2431,  3.5747,  2.0912],\n",
            "        [-2.0862,  1.5442, -2.3530,  5.4501],\n",
            "        [ 0.2040,  2.3356, -2.2486,  3.2761],\n",
            "        [ 1.2203, -0.2707,  2.5179,  0.8418],\n",
            "        [-1.5180, -0.2862,  1.1190,  3.2532],\n",
            "        [-2.2141, -0.9713,  1.2437,  0.3484]])\n",
            "\n",
            "Raw Attention Scores:\n",
            "tensor([[ -6.8058,   2.9152,   8.6675,  -4.5268,  -5.9328,  -5.8111],\n",
            "        [ -0.1635,  -1.6268,   4.3083,   0.5273,  -2.9649,  -1.1253],\n",
            "        [-10.8165,   6.2818,  14.0315,  -7.4619,  -8.5411,  -9.3895],\n",
            "        [ -4.4443,   2.4660,   5.9200,  -3.0756,  -3.7546,  -4.1664],\n",
            "        [  3.6419,  -2.9838,   0.1568,   2.9603,  -0.0587,   1.2344],\n",
            "        [  6.8808,  -2.4610,  -2.8972,   4.7027,   3.0349,   2.5512]])\n",
            "\n",
            "Attention Weights (after softmax):\n",
            "tensor([[1.8995e-07, 3.1653e-03, 9.9683e-01, 1.8553e-06, 4.5475e-07, 5.1360e-07],\n",
            "        [1.0967e-02, 2.5386e-03, 9.5975e-01, 2.1882e-02, 6.6600e-04, 4.1916e-03],\n",
            "        [1.6160e-11, 4.3067e-04, 9.9957e-01, 4.6274e-10, 1.5727e-10, 6.7326e-11],\n",
            "        [3.0565e-05, 3.0642e-02, 9.6911e-01, 1.2013e-04, 6.0918e-05, 4.0357e-05],\n",
            "        [6.0513e-01, 8.0231e-04, 1.8548e-02, 3.0607e-01, 1.4953e-02, 5.4490e-02],\n",
            "        [8.7113e-01, 7.6382e-05, 4.9380e-05, 9.8659e-02, 1.8614e-02, 1.1475e-02]])\n",
            "\n",
            "Output:\n",
            "tensor([[ 0.1968,  2.3331, -2.2490,  3.2830],\n",
            "        [ 0.2281,  2.2327, -2.0639,  3.2031],\n",
            "        [ 0.2031,  2.3353, -2.2487,  3.2771],\n",
            "        [ 0.1338,  2.3107, -2.2508,  3.3423],\n",
            "        [ 1.3988, -0.2426,  2.9747,  1.6559],\n",
            "        [ 1.7458, -0.2547,  3.3972,  1.9699]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def self_attention(input_sentence):\n",
        "    \"\"\"Compute self-attention for a given input sentence\"\"\"\n",
        "\n",
        "    tokens = input_sentence.split()\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    embedding_dim = 4\n",
        "    vocab_size = len(tokens)\n",
        "\n",
        "\n",
        "    embeddings = torch.randn(len(tokens), embedding_dim)\n",
        "    print(f\"\\nEmbeddings:\\n{embeddings}\")\n",
        "\n",
        "\n",
        "    positions = torch.arange(len(tokens)).unsqueeze(1)\n",
        "    position_enc = torch.zeros(len(tokens), embedding_dim)\n",
        "\n",
        "    for pos in range(len(tokens)):\n",
        "        for i in range(0, embedding_dim, 2):\n",
        "            position_enc[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embedding_dim)))\n",
        "            if i+1 < embedding_dim:\n",
        "                position_enc[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1))/embedding_dim)))\n",
        "\n",
        "    print(f\"\\nPositional Encodings:\\n{position_enc}\")\n",
        "\n",
        "    X = embeddings + position_enc\n",
        "    print(f\"\\nInput with Positional Encoding (X):\\n{X}\")\n",
        "\n",
        "\n",
        "    d_k = embedding_dim\n",
        "    W_Q = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_K = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_V = torch.randn(embedding_dim, embedding_dim)\n",
        "\n",
        "    print(f\"\\nWeight Matrices:\")\n",
        "    print(f\"W_Q:\\n{W_Q}\")\n",
        "    print(f\"W_K:\\n{W_K}\")\n",
        "    print(f\"W_V:\\n{W_V}\")\n",
        "\n",
        "\n",
        "    Q = torch.matmul(X, W_Q)\n",
        "    K = torch.matmul(X, W_K)\n",
        "    V = torch.matmul(X, W_V)\n",
        "\n",
        "    print(f\"\\nQuery Matrix (Q):\\n{Q}\")\n",
        "    print(f\"Key Matrix (K):\\n{K}\")\n",
        "    print(f\"Value Matrix (V):\\n{V}\")\n",
        "\n",
        "\n",
        "    attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    print(f\"\\nRaw Attention Scores:\\n{attention_scores}\")\n",
        "\n",
        "\n",
        "    attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "    print(f\"\\nAttention Weights (after softmax):\\n{attention_weights}\")\n",
        "\n",
        "\n",
        "    output = torch.matmul(attention_weights, V)\n",
        "    print(f\"\\nOutput:\\n{output}\")\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "input_sentence = \"What are the symptoms of diabetes\"\n",
        "output, attn_weights = self_attention(input_sentence)"
      ]
    }
  ]
}