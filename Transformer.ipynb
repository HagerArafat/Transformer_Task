{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSANnVcxeAxv0VxRa1LKQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HagerArafat/Transformer_Task/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aEJM87QCuoD",
        "outputId": "ab7fda48-e7d4-40e8-8968-6080942b95c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['What', 'are', 'the', 'symptoms', 'of', 'diabetes']\n",
            "\n",
            "Embeddings:\n",
            "tensor([[ 0.4744, -0.5460, -0.8796, -0.8389],\n",
            "        [-0.7847, -0.3881, -0.9419,  1.4942],\n",
            "        [-2.2813, -1.0201, -0.2815,  0.4560],\n",
            "        [-0.7261, -1.3515,  0.5665,  0.6561],\n",
            "        [ 0.4203, -0.6492, -1.1377,  0.4314],\n",
            "        [ 0.5649, -2.6623,  0.7305,  0.7320]])\n",
            "\n",
            "PE:\n",
            "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  9.9995e-01,  1.0000e-04,  1.0000e+00],\n",
            "        [ 9.0930e-01,  9.9980e-01,  2.0000e-04,  1.0000e+00],\n",
            "        [ 1.4112e-01,  9.9955e-01,  3.0000e-04,  1.0000e+00],\n",
            "        [-7.5680e-01,  9.9920e-01,  4.0000e-04,  1.0000e+00],\n",
            "        [-9.5892e-01,  9.9875e-01,  5.0000e-04,  1.0000e+00]])\n",
            "\n",
            "Input with PE (X):\n",
            "tensor([[ 0.4744,  0.4540, -0.8796,  0.1611],\n",
            "        [ 0.0568,  0.6118, -0.9418,  2.4942],\n",
            "        [-1.3720, -0.0203, -0.2813,  1.4560],\n",
            "        [-0.5850, -0.3519,  0.5668,  1.6561],\n",
            "        [-0.3365,  0.3500, -1.1373,  1.4314],\n",
            "        [-0.3940, -1.6635,  0.7310,  1.7320]])\n",
            "\n",
            "Weight Matrices:\n",
            "WQ:\n",
            "tensor([[-0.3410, -1.0043, -0.5225,  0.7643],\n",
            "        [ 0.2071, -0.4335, -0.1293,  0.0354],\n",
            "        [-0.1792,  1.2370,  0.4422,  1.5479],\n",
            "        [ 1.1688,  0.9827,  0.4187, -0.4330]])\n",
            "WK:\n",
            "tensor([[ 1.7381,  1.1570, -0.2459,  0.1186],\n",
            "        [ 0.9389, -0.7182,  0.4277, -1.2411],\n",
            "        [-1.1535,  0.5588, -0.6286, -1.2796],\n",
            "        [-0.1196,  0.8977,  0.9680,  0.8293]])\n",
            "WV:\n",
            "tensor([[-0.4072,  0.1398,  0.4850, -1.6129],\n",
            "        [ 0.2826, -0.7984, -0.9246,  1.1514],\n",
            "        [-0.3043, -0.4317,  1.0155,  0.0827],\n",
            "        [ 0.6111, -1.2108, -0.5689,  0.7588]])\n",
            "\n",
            " (Q):\n",
            "tensor([[ 0.2781, -1.6031, -0.6281, -1.0527],\n",
            "        [ 3.1913,  0.9638,  0.5192, -2.4728],\n",
            "        [ 2.2157,  2.4695,  1.2048, -2.1153],\n",
            "        [ 1.9607,  3.0685,  1.2953, -0.2993],\n",
            "        [ 2.0639,  0.1860,  0.2270, -2.6252],\n",
            "        [ 1.6832,  3.7231,  1.4695,  0.0217]])\n",
            "(K):\n",
            "tensor([[ 2.2463, -0.1240,  0.7863,  0.7520],\n",
            "        [ 1.4613,  1.3392,  3.2541,  2.5209],\n",
            "        [-2.2533, -0.4230,  1.9149,  1.4298],\n",
            "        [-2.1990,  1.3794,  1.2401,  1.0155],\n",
            "        [ 0.8845,  0.0087,  2.3329,  2.1681],\n",
            "        [-3.2972,  2.7021,  0.6024,  2.5187]])\n",
            "(V):\n",
            "tensor([[ 0.3012, -0.1115, -1.1745, -0.1930],\n",
            "        [ 1.9606, -3.0940, -2.9136,  2.4277],\n",
            "        [ 1.5283, -1.8170, -1.7607,  3.2711],\n",
            "        [ 0.9783, -2.0507, -0.3250,  1.8419],\n",
            "        [ 1.4568, -1.5686, -2.4561,  1.9379],\n",
            "        [ 0.5263, -1.1395,  1.1040,  0.0949]])\n",
            "\n",
            "Raw Attention Scores:\n",
            "tensor([[-0.2310, -3.2190, -1.3282, -2.3353, -1.7578, -4.1391],\n",
            "        [ 2.7988,  0.7048, -5.0701, -3.7777, -0.6596, -6.9167],\n",
            "        [ 2.0138,  2.5663, -3.3775, -1.0601,  0.1028, -2.6175],\n",
            "        [ 2.4085,  5.2173, -1.8319,  0.6118,  2.0668,  0.9266],\n",
            "        [ 1.4088, -1.3071, -4.0241, -3.3332, -1.6675, -6.3889],\n",
            "        [ 2.2454,  6.1410, -1.2613,  1.6394,  2.4982,  2.7252]])\n",
            "\n",
            "Attention Weights (after softmax):\n",
            "tensor([[5.7359e-01, 2.8900e-02, 1.9146e-01, 6.9935e-02, 1.2460e-01, 1.1516e-02],\n",
            "        [8.6467e-01, 1.0652e-01, 3.3070e-04, 1.2042e-03, 2.7220e-02, 5.2175e-05],\n",
            "        [3.3943e-01, 5.8981e-01, 1.5465e-03, 1.5696e-02, 5.0214e-02, 3.3068e-03],\n",
            "        [5.3452e-02, 8.8679e-01, 7.6985e-04, 8.8646e-03, 3.7981e-02, 1.2145e-02],\n",
            "        [8.8827e-01, 5.8757e-02, 3.8822e-03, 7.7472e-03, 4.0978e-02, 3.6480e-04],\n",
            "        [1.8634e-02, 9.1654e-01, 5.5891e-04, 1.0165e-02, 2.3993e-02, 3.0109e-02]])\n",
            "\n",
            "Output:\n",
            "tensor([[ 0.7780, -0.8532, -1.4111,  0.9571],\n",
            "        [ 0.5107, -0.4718, -1.3937,  0.1478],\n",
            "        [ 1.3512, -1.9802, -2.2446,  1.4980],\n",
            "        [ 1.8263, -2.8427, -2.7306,  2.2362],\n",
            "        [ 0.4562, -0.3684, -1.3241,  0.0776],\n",
            "        [ 1.8642, -2.9317, -2.7223,  2.2914]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def self_attention(input_sentence):\n",
        "    \"\"\"Compute self-attention for a given input sentence\"\"\"\n",
        "\n",
        "    tokens = input_sentence.split()\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    embedding_dim = 4\n",
        "    vocab_size = len(tokens)\n",
        "\n",
        "\n",
        "    embeddings = torch.randn(len(tokens), embedding_dim)\n",
        "    print(f\"\\nEmbeddings:\\n{embeddings}\")\n",
        "\n",
        "\n",
        "    positions = torch.arange(len(tokens)).unsqueeze(1)\n",
        "    position_enc = torch.zeros(len(tokens), embedding_dim)\n",
        "\n",
        "    for pos in range(len(tokens)):\n",
        "        for i in range(0, embedding_dim, 2):\n",
        "            position_enc[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embedding_dim)))\n",
        "            if i+1 < embedding_dim:\n",
        "                position_enc[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1))/embedding_dim)))\n",
        "\n",
        "    print(f\"\\nPE:\\n{position_enc}\")\n",
        "\n",
        "    X = embeddings + position_enc\n",
        "    print(f\"\\nInput with PE (X):\\n{X}\")\n",
        "\n",
        "\n",
        "    d_k = embedding_dim\n",
        "    W_Q = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_K = torch.randn(embedding_dim, embedding_dim)\n",
        "    W_V = torch.randn(embedding_dim, embedding_dim)\n",
        "\n",
        "    print(f\"\\nWeight Matrices:\")\n",
        "    print(f\"WQ:\\n{W_Q}\")\n",
        "    print(f\"WK:\\n{W_K}\")\n",
        "    print(f\"WV:\\n{W_V}\")\n",
        "\n",
        "\n",
        "    Q = torch.matmul(X, W_Q)\n",
        "    K = torch.matmul(X, W_K)\n",
        "    V = torch.matmul(X, W_V)\n",
        "\n",
        "    print(f\"\\n (Q):\\n{Q}\")\n",
        "    print(f\"(K):\\n{K}\")\n",
        "    print(f\"(V):\\n{V}\")\n",
        "\n",
        "\n",
        "    attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    print(f\"\\nRaw Attention Scores:\\n{attention_scores}\")\n",
        "\n",
        "\n",
        "    attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "    print(f\"\\nAttention Weights (after softmax):\\n{attention_weights}\")\n",
        "\n",
        "\n",
        "    output = torch.matmul(attention_weights, V)\n",
        "    print(f\"\\nOutput:\\n{output}\")\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "input_sentence = \"What are the symptoms of diabetes\"\n",
        "output, attn_weights = self_attention(input_sentence)"
      ]
    }
  ]
}